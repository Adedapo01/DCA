//-*-C++-*-

#ifndef CACHED_DELAYED_NFFT_1D_H
#define CACHED_DELAYED_NFFT_1D_H

namespace MATK_ALGORITHMS
{
  namespace NFFT
  {
    /*! \file cached_auxilery_field_values.h
     *
     *  \author Peter Staar
     *  \author Raffaele Solca'
     *
     *  Contains a templated class over the dimension to represent the cached nfft-plan
     *  this class does only 1 FT, at the end of the accumulation if the error is not measured !!!
     */
    template<typename scalartype, typename w_dmn_t, typename p_dmn_t>
    class dnfft_1D
    {
#include "type_definitions.h"

      const static int    m     = 8;
      const static int    STEP  = 32;

      typedef dmn_0<extended_time_domain   <m      , w_dmn_t> > extended_time_dmn_t;
      typedef dmn_0<fine_time_domain       <m, STEP, w_dmn_t> > fine_time_dmn_t;
//       typedef dmn_0<folded_fine_time_domain<m, STEP, w_dmn_t> > folded_fine_time_dmn_t;

      typedef dmn_2<extended_time_dmn_t, p_dmn_t > ext_t__nu_nu_r_DCA;

      //typedef gaussian_window_function window_function_t;
      typedef kaiser_bessel_function<1> window_function_t;

    public:

      dnfft_1D(int Nb_freqs);
      ~dnfft_1D();

      void initialize();

      void accumulate_at(int* coor, scalartype t_val, scalartype f_val);

      void accumulate_at(int* coor, int size, scalartype* t_vals, scalartype* f_vals);

      void finalize(function<std::complex<double>, dmn_2<w, p_dmn_t> >& f_w);

      template<typename cluster_dmn_t>
      void finalize(function<std::complex<double>, dmn_4<nu,nu,cluster_dmn_t,w> >& f_w);

    private:

      void initialize_time_domains();

      void initialize_linear_interpolation_functions();
      void initialize_cubic_interpolation_functions();
//       void initialize_folded_cubic_interpolation_functions();

      inline void convolute_to_f_tau_exact               (int index, scalartype tau, scalartype f_val);

      inline void convolute_to_f_tau_linear_interpolation(int index, scalartype tau, scalartype f_val);
      inline void convolute_to_f_tau_cubic_interpolation (int index, scalartype tau, scalartype f_val);

      inline void convolute_to_f_tau_fine_linear_interpolation(int index, scalartype t_val, scalartype f_val);
      inline void convolute_to_f_tau_fine_cubic_interpolation(int index, scalartype t_val, scalartype f_val);
      inline void convolute_to_f_tau_fine_cubic_interpolation_fast(int index, scalartype t_val, scalartype f_val);

      void fold_time_domain_back();

      void FT_f_tau_to_f_w(function<std::complex<double>, dmn_2<w, p_dmn_t> >& f_w);

      template<typename cluster_dmn_t>
      void FT_f_tau_to_f_w(function<std::complex<double>, dmn_4<nu,nu,cluster_dmn_t,w> >& f_w);

    private:

      const double sigma;// = 2;

      double N_w, N_t, b_val, one_div_N_t;

      scalartype t_0_ext, t_0_fine ,one_div_delta_t ,one_div_fine_delta_t;

      p_dmn_t p_dmn_t_obj;

      function<scalartype, ext_t__nu_nu_r_DCA> f_tau;

      function<scalartype, extended_time_dmn_t> tau;

      function<scalartype, fine_time_dmn_t> fine_tau;

      function<scalartype, fine_time_dmn_t>     fine_phi_tau;
      function<scalartype, fine_time_dmn_t> fine_der_phi_tau;


      function<scalartype, fine_time_dmn_t> fine_alpha;
      function<scalartype, fine_time_dmn_t> fine_beta ;
      function<scalartype, fine_time_dmn_t> fine_gamma;
      function<scalartype, fine_time_dmn_t> fine_delta;

//       function<scalartype, dmn_2< dmn_0<dmn<4*m, int> >, dmn_0<dmn<STEP, int> > > > folded_fine_tau;
//       function<scalartype, dmn_2< dmn_0<dmn<4*m, int> >, dmn_0<dmn<STEP, int> > > > folded_fine_alpha;
//       function<scalartype, dmn_2< dmn_0<dmn<4*m, int> >, dmn_0<dmn<STEP, int> > > > folded_fine_beta;
//       function<scalartype, dmn_2< dmn_0<dmn<4*m, int> >, dmn_0<dmn<STEP, int> > > > folded_fine_gamma;
//       function<scalartype, dmn_2< dmn_0<dmn<4*m, int> >, dmn_0<dmn<STEP, int> > > > folded_fine_delta;

      typedef dmn_0<dmn<4  , int> > row_dmn_t;
      typedef dmn_0<dmn<4*m, int> > col_dmn_t;

      //
      function<scalartype, row_dmn_t> y_values;

      // the convolution-matrices are row-major, to maximize data-locality!
      function<scalartype, dmn_3<row_dmn_t, col_dmn_t, dmn_0<dmn<STEP, int> > > > convolution_matrices;

      function<double, w >                  phi_wn;
    };

    template<typename scalartype, typename w_dmn_t, typename p_dmn_t>
    dnfft_1D<scalartype, w_dmn_t, p_dmn_t>::dnfft_1D(int Nb_freqs):
      sigma(2.),

      N_w(Nb_freqs),
      N_t(extended_time_dmn_t::dmn_size()),//m*N_w),

      b_val(m/M_PI*(2*sigma)/(2*sigma-1)),

      one_div_N_t(1./double(N_t))
    {
      assert(w::dmn_size()/2 == Nb_freqs);

      {
        t_0_ext  = extended_time_dmn_t::get_elements()[0];
        t_0_fine = fine_time_dmn_t    ::get_elements()[0];

        one_div_delta_t      = 1./(extended_time_dmn_t::get_elements()[1]-extended_time_dmn_t::get_elements()[0]);
        one_div_fine_delta_t = 1./(fine_time_dmn_t::get_elements()[1]-fine_time_dmn_t::get_elements()[0]);
      }

      window_function_t::n = N_t;
      window_function_t::m = m;

      window_function_t::sigma = sigma;

      //kaiser_bessel_function::test_besselI0();

      double delta_t = (1./N_t);

      { // time domains ...
        for(int l=0; l<tau.size(); l++)
          tau(l) = extended_time_dmn_t::get_elements()[l];

        for(int l=0; l<fine_tau.size(); l++)
          fine_tau(l) = fine_time_dmn_t::get_elements()[l];
      }

      { // initialize linear-interpolation
        for(int l=0; l<fine_phi_tau.size(); l++)
          fine_phi_tau(l) = window_function_t::phi_t(fine_tau(l));

        for(int l=0; l<fine_der_phi_tau.size()-1; l++)
          fine_der_phi_tau(l) = (window_function_t::phi_t(fine_tau(l+1))-window_function_t::phi_t(fine_tau(l)))/delta_t;
      }

      { // initialize cubic-interpolation
        for(int l=0; l<fine_tau.size(); l++)
          fine_alpha(l) = window_function_t::phi_t(fine_tau(l));

        for(int l=0; l<fine_tau.size(); l++)
          fine_beta(l)  = window_function_t::d_phi_t(fine_tau(l));

        for(int l=0; l<fine_tau.size()-1; l++){
          delta_t = fine_tau(l+1)-fine_tau(l);

          double f0 = window_function_t::phi_t(fine_tau(l));
          double f1 = window_function_t::phi_t(fine_tau(l+1));

          double df0 = window_function_t::d_phi_t(fine_tau(l));
          double df1 = window_function_t::d_phi_t(fine_tau(l+1));

          fine_gamma(l) = -(3.*f0-3.*f1+2.*df0*delta_t+df1*delta_t)/square(delta_t);
        }

        for(int l=0; l<fine_tau.size()-1; l++){
          delta_t = fine_tau(l+1)-fine_tau(l);

          double f0 = window_function_t::phi_t(fine_tau(l));
          double f1 = window_function_t::phi_t(fine_tau(l+1));

          double df0 = window_function_t::d_phi_t(fine_tau(l));
          double df1 = window_function_t::d_phi_t(fine_tau(l+1));

          fine_delta(l) = -(-2.*f0+2.*f1-df0*delta_t-df1*delta_t)/(delta_t*delta_t*delta_t);
        }
      }

//       {
//         int nb_col = STEP;
//         int nb_row = 4*m;

//         for(int j=0; j<nb_col; j++){
//           for(int i=0; i<nb_row; i++){
//             folded_fine_tau(i,j) = folded_fine_time_dmn_t::get_elements()[i+j*nb_row];
//             assert( fabs(folded_fine_tau(i,j)-fine_tau(i*STEP+j))<1.e-6);

//             folded_fine_alpha(i,j) = fine_alpha(i*STEP+j);
//             folded_fine_beta (i,j) = fine_beta (i*STEP+j);
//             folded_fine_gamma(i,j) = fine_gamma(i*STEP+j);
//             folded_fine_delta(i,j) = fine_delta(i*STEP+j);

//             convolution_matrices(0, i, j) = fine_alpha(i*STEP+j);
//             convolution_matrices(1, i, j) = fine_beta (i*STEP+j);
//             convolution_matrices(2, i, j) = fine_gamma(i*STEP+j);
//             convolution_matrices(3, i, j) = fine_delta(i*STEP+j);
//           }
//         }
//       }

      for(int l=0; l<w::dmn_size(); l++)
        phi_wn(l) = window_function_t::phi_wn(2*(l-N_w)+1);
    }

    template<typename scalartype, typename w_dmn_t, typename p_dmn_t>
    dnfft_1D<scalartype, w_dmn_t, p_dmn_t>::~dnfft_1D()
    {}

    template<typename scalartype, typename w_dmn_t, typename p_dmn_t>
    void dnfft_1D<scalartype, w_dmn_t, p_dmn_t>::initialize()
    {
      f_tau         = 0.;
    }

    template<typename scalartype, typename w_dmn_t, typename p_dmn_t>
    inline void dnfft_1D<scalartype, w_dmn_t, p_dmn_t>::accumulate_at(int* coor, scalartype t_val, scalartype f_val)
    {
      int linind=0;
      p_dmn_t_obj.subind_2_linind(coor, linind);

      //convolute_to_f_tau_exact(linind, t_vals[l], f_vals[l]);
      //convolute_to_f_tau_fine_linear_interpolation(linind, t_vals[l], f_vals[l]);

      //convolute_to_f_tau_fine_cubic_interpolation(linind, t_val, f_val);
      convolute_to_f_tau_fine_cubic_interpolation_fast(linind, t_val, f_val);
    }

    template<typename scalartype, typename w_dmn_t, typename p_dmn_t>
    void dnfft_1D<scalartype, w_dmn_t, p_dmn_t>::finalize(function<std::complex<double>, dmn_2<w, p_dmn_t> >& f_w)
    {
      fold_time_domain_back();

      FT_f_tau_to_f_w(f_w);
    }

    template<typename scalartype, typename w_dmn_t, typename p_dmn_t>
    template<typename cluster_dmn_t>
    void dnfft_1D<scalartype, w_dmn_t, p_dmn_t>::finalize(function<std::complex<double>, dmn_4<nu,nu,cluster_dmn_t,w> >& f_w)
    {
      fold_time_domain_back();

      FT_f_tau_to_f_w(f_w);
    }

    /*************************************************************
     **                                                         **
     **                                                         **
     **                  private functions                      **
     **                                                         **
     **                                                         **
     *************************************************************/

    template<typename scalartype, typename w_dmn_t, typename p_dmn_t>
    void dnfft_1D<scalartype, w_dmn_t, p_dmn_t>::convolute_to_f_tau_exact(int index, scalartype t_val, scalartype f_val)
    {
      int lambda_0, tau_index, l;
      scalartype  phi_interp;

      lambda_0 = one_div_delta_t*(t_val-t_0_ext);

      for(l=-m; l<=m; l++){

        tau_index       = lambda_0+l;

        phi_interp = window_function_t::phi_t(tau(lambda_0)-t_val+l/one_div_delta_t);

        f_tau(tau_index, index) += f_val*phi_interp;
      }
    }

    template<typename scalartype, typename w_dmn_t, typename p_dmn_t>
    void dnfft_1D<scalartype, w_dmn_t, p_dmn_t>::convolute_to_f_tau_fine_linear_interpolation(int index, scalartype t_val, scalartype f_val)
    {
      int lambda_0, lambda_1,  tau_index,  delta_tau_index;
      scalartype diff_tau;

      lambda_0 = one_div_delta_t*(t_val-t_0_ext);

      lambda_1 = ( tau(lambda_0)-t_val - t_0_fine)*one_div_fine_delta_t;
      assert(fine_tau(lambda_1  ) <= tau(lambda_0)-t_val);
      assert(fine_tau(lambda_1+1) >= tau(lambda_0)-t_val);

      diff_tau = tau(lambda_0)-t_val-fine_tau(lambda_1);

      tau_index       = lambda_0-m;
      delta_tau_index = lambda_1-m*STEP;

      atomic_convolution<m, STEP>::execute(&f_tau(tau_index, index), diff_tau, f_val, &fine_der_phi_tau(delta_tau_index), &fine_phi_tau(delta_tau_index));
    }

    template<typename scalartype, typename w_dmn_t, typename p_dmn_t>
    inline void dnfft_1D<scalartype, w_dmn_t, p_dmn_t>::convolute_to_f_tau_fine_cubic_interpolation(int index, scalartype t_val, scalartype f_val)
    {
      //scalartype diff_tau[3];
      scalartype* diff_tau = new scalartype[3];

      int lambda_0 = (t_val-t_0_ext)*one_div_delta_t;

      //     assert(tau(lambda_0)-1.e-6<t_val&& t_val<tau(lambda_0+1)+1.e-6 );

      int lambda_1 = (tau(lambda_0)-t_val - t_0_fine)*one_div_fine_delta_t;

      //     assert(fine_tau(lambda_1  ) - (tau(lambda_0)-t_val) <  1.e-6);
      //     assert(fine_tau(lambda_1+1) - (tau(lambda_0)-t_val) > -1.e-6);

      diff_tau[0] = tau(lambda_0)-t_val-fine_tau(lambda_1);
      diff_tau[1] = diff_tau[0]*diff_tau[0];
      diff_tau[2] = diff_tau[0]*diff_tau[1];

      int tau_index       = lambda_0-m;
      int delta_tau_index = lambda_1-m*STEP;

      assert(     tau(lambda_0)-1.e-10 < t_val               && t_val               <      tau(lambda_0+1)+1.e-10);
      assert(fine_tau(lambda_1)-1.e-10 < tau(lambda_0)-t_val && tau(lambda_0)-t_val < fine_tau(lambda_1+1)+1.e-10);

      atomic_convolution<m,STEP>::execute(&f_tau(tau_index, index), diff_tau, f_val,
                                          &fine_alpha(delta_tau_index), &fine_beta (delta_tau_index),
                                          &fine_gamma(delta_tau_index), &fine_delta(delta_tau_index));

      delete [] diff_tau;
    }

    template<typename scalartype, typename w_dmn_t, typename p_dmn_t>
    inline void dnfft_1D<scalartype, w_dmn_t, p_dmn_t>::convolute_to_f_tau_fine_cubic_interpolation_fast(int index, scalartype t_val, scalartype f_val)
    {
      //     static scalartype* y = new scalartype[4];
      //     scalartype* y = new scalartype[4];
      scalartype* y = &y_values(0);

      int lambda_0 = (t_val-t_0_ext)*one_div_delta_t;

      //     assert(tau(lambda_0)-1.e-6<t_val&& t_val<tau(lambda_0+1)+1.e-6 );

      int lambda_1 = (tau(lambda_0)-t_val - t_0_fine)*one_div_fine_delta_t;

      //     assert(fine_tau(lambda_1  ) - (tau(lambda_0)-t_val) <  1.e-6);
      //     assert(fine_tau(lambda_1+1) - (tau(lambda_0)-t_val) > -1.e-6);

      double diff_tau = tau(lambda_0)-t_val-fine_tau(lambda_1);

      y[0] = f_val;
      y[1] = f_val*diff_tau;
      y[2] = f_val*pow(diff_tau,2);
      y[3] = f_val*pow(diff_tau,3);

      int tau_index       = lambda_0-m;
      int delta_tau_index = lambda_1-m*STEP;

      assert(     tau(lambda_0)-1.e-10 < t_val               && t_val               <      tau(lambda_0+1)+1.e-10);
      assert(fine_tau(lambda_1)-1.e-10 < tau(lambda_0)-t_val && tau(lambda_0)-t_val < fine_tau(lambda_1+1)+1.e-10);

      {
        // delta_tau_index = I*STEP+J;
        int J =  delta_tau_index   %STEP;
        int I = (delta_tau_index-J)/STEP;
        assert(delta_tau_index == I*STEP+J);

        atomic_convolution_sse<2*m+1,0>::execute(&f_tau(tau_index, index), y, &convolution_matrices(0,I,J));
      }
    }

    template<typename scalartype, typename w_dmn_t, typename p_dmn_t>
    void dnfft_1D<scalartype, w_dmn_t, p_dmn_t>::fold_time_domain_back()
    {
      int N = extended_time_dmn_t::dmn_size();

      for(int l=0; l<p_dmn_t_obj.get_size(); l++){

        for(int i=0; i<2*m; i++)
          {
            assert(extended_time_dmn_t::get_elements()[i]<-0.5000001);
            assert(extended_time_dmn_t::get_elements()[N-4*m+i]< 0.4999999);
            assert(fabs(extended_time_dmn_t::get_elements()[N-4*m+i]-extended_time_dmn_t::get_elements()[i] -1.)<1.e-6);

            f_tau(N-4*m+i,l) += f_tau(i,l);
            f_tau(      i,l)  = 0;
          }

        for(int i=0; i<2*m; i++)
          {
            assert(extended_time_dmn_t::get_elements()[2*m+i]>-0.5000001);
            assert(extended_time_dmn_t::get_elements()[N-2*m+i]>0.4999999);

            f_tau(  2*m+i,l) += f_tau(N-2*m+i,l);
            f_tau(N-2*m+i,l) = 0;
          }
      }
    }

    template<typename scalartype, typename w_dmn_t, typename p_dmn_t>
    void dnfft_1D<scalartype, w_dmn_t, p_dmn_t>::FT_f_tau_to_f_w(function<std::complex<double>, dmn_2<w, p_dmn_t> >& f_w)
    {
      nfft_plan nfft;

      int Nb_freq  =   w::dmn_size();
      int Nb_times = m*w::dmn_size()/2;

      nfft_init_1d(&nfft, 2*Nb_freq, Nb_times); // --> '2*' accounts for even frequencies

      for(int i=0; i<Nb_times; i++){
        int I =  2*m+i;
        nfft.x[i] = extended_time_dmn_t::get_elements()[I];
      }

      if(nfft.nfft_flags & PRE_ONE_PSI)
        nfft_precompute_one_psi(&nfft);

      for(int l=0; l<p_dmn_t_obj.get_size(); l++)
        {
          memset(nfft.f,     0.,   Nb_times*sizeof(std::complex<double>) );
          memset(nfft.f_hat, 0., 2*Nb_freq *sizeof(std::complex<double>) );

          for(int i=0; i<Nb_times; i++)
            {
              int I = 2*m+i;
              assert(extended_time_dmn_t::get_elements()[I]>-0.5000001
                     && extended_time_dmn_t::get_elements()[I]<0.5);

              nfft.f[i][0] = f_tau(I,l);
              nfft.f[i][1] = 0;
            }

          nfft_adjoint(&nfft);

          std::complex<double> c;
          for(int i=0; i<Nb_freq; i++){
            c = std::complex<double>(nfft.f_hat[2*i+1][0], nfft.f_hat[2*i+1][1])/window_function_t::phi_wn(2*(i-Nb_freq/2)+1)/double(Nb_times);
            f_w(i, l) = c;
          }
        }

      nfft_finalize(&nfft);
    }

    template<typename scalartype, typename w_dmn_t, typename p_dmn_t>
    template<typename cluster_dmn_t>
    void dnfft_1D<scalartype, w_dmn_t, p_dmn_t>::FT_f_tau_to_f_w(function<std::complex<double>, dmn_4<nu,nu,cluster_dmn_t,w> >& M_r_w)
    {
      nfft_plan nfft;

      int Nb_freq  =   w::dmn_size();
      int Nb_times = m*w::dmn_size()/2;

      nfft_init_1d(&nfft, 2*Nb_freq, Nb_times); // --> '2*' accounts for even frequencies

      for(int i=0; i<Nb_times; i++){
        int I =  2*m+i;
        nfft.x[i] = extended_time_dmn_t::get_elements()[I];
      }

      if(nfft.nfft_flags & PRE_ONE_PSI)
        nfft_precompute_one_psi(&nfft);

      int linind, coor[5];

      for(int l=0; l<p_dmn_t_obj.get_size(); l++)
        {
          linind=l;
          memset(coor, 0, 5*sizeof(int));
          p_dmn_t_obj.linind_2_subind(linind, coor);

          memset(nfft.f,     0.,   Nb_times*sizeof(std::complex<double>) );
          memset(nfft.f_hat, 0., 2*Nb_freq *sizeof(std::complex<double>) );

          for(int i=0; i<Nb_times; i++)
            {
              int I = 2*m+i;
              assert(extended_time_dmn_t::get_elements()[I]>-0.5000001 && extended_time_dmn_t::get_elements()[I]<0.5);

              nfft.f[i][0] = f_tau(I,l);
              nfft.f[i][1] = 0;
            }

          nfft_adjoint(&nfft);

          std::complex<double> c;
          for(int i=0; i<Nb_freq; i++){
            c = std::complex<double>(nfft.f_hat[2*i+1][0], nfft.f_hat[2*i+1][1])/window_function_t::phi_wn(2*(i-Nb_freq/2)+1)/double(Nb_times);
            M_r_w(coor[0], coor[1], coor[2], coor[3], coor[4], i) = c;
          }
        }

      nfft_finalize(&nfft);
    }

  }

}

#endif
